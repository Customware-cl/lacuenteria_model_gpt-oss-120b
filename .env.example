# Configuración del modelo LLM
LLM_API_URL=http://localhost:8000/v1/chat/completions
LLM_MODEL=openai/gpt-oss-120b
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=20000
LLM_TIMEOUT=900

# Configuración de la API
API_HOST=0.0.0.0
API_PORT=5000
CORS_ORIGINS=https://lacuenteria.cl,http://localhost:3000
DEBUG=False

# Configuración de calidad
MIN_QA_SCORE=4.0
MAX_RETRIES=2
RETRY_DELAY=5

# Configuración de webhooks
WEBHOOK_TIMEOUT=30
WEBHOOK_MAX_ATTEMPTS=3
WEBHOOK_RETRY_DELAY=10

# Configuración de procesamiento
MAX_CONCURRENT_STORIES=3
STORY_TIMEOUT=600
CLEANUP_AFTER_DAYS=30

# Logging
LOG_LEVEL=INFO