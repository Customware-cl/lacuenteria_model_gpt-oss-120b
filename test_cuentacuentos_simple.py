#!/usr/bin/env python3
"""
Test simple y directo del cuentacuentos
"""
import json
import sys
import time

sys.path.append('/home/ubuntu/cuenteria/src')

from llm_client import LLMClient

def test_simple():
    print("="*70)
    print("üß™ TEST SIMPLE DEL CUENTACUENTOS")
    print("="*70)
    
    # Cliente LLM - usar el singleton configurado
    from llm_client import get_llm_client
    client = get_llm_client()
    client.timeout = 120  # Timeout m√°s corto para prueba r√°pida
    
    # Prompt m√≠nimo del sistema
    system_prompt = """Eres un cuentacuentos. Genera un cuento de 10 p√°ginas en verso.
Cada p√°gina debe tener exactamente 4 versos.
Devuelve un JSON con este formato exacto:
{
  "paginas_texto": {
    "1": "verso1\\nverso2\\nverso3\\nverso4",
    "2": "verso1\\nverso2\\nverso3\\nverso4",
    ...hasta p√°gina 10
  },
  "leitmotiv_usado_en": [2, 5, 10]
}"""

    # Prompt m√≠nimo del usuario
    user_prompt = """Crea un cuento sobre Emilia y un pastel de cumplea√±os.
El leitmotiv es: "¬°Tic, tac, la canci√≥n del pastel!"
Usa el leitmotiv en p√°ginas 2, 5 y 10.
Devuelve SOLO el JSON, sin explicaciones."""

    print(f"\nüìä Tama√±os:")
    print(f"   System: {len(system_prompt)} chars")
    print(f"   User: {len(user_prompt)} chars")
    print(f"   Total: {len(system_prompt) + len(user_prompt)} chars")
    
    # Probar diferentes configuraciones
    configs = [
        (2000, 0.7),   # M√≠nimo
        (4000, 0.7),   # Est√°ndar
        (6000, 0.7),   # Aumentado
        (8000, 0.7),   # Alto
    ]
    
    for max_tokens, temp in configs:
        print(f"\nüîß Probando max_tokens={max_tokens}, temp={temp}")
        
        try:
            start = time.time()
            result = client.generate(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=temp,
                max_tokens=max_tokens
            )
            elapsed = time.time() - start
            
            print(f"‚úÖ √âXITO en {elapsed:.1f}s")
            
            # Verificar resultado
            if isinstance(result, str):
                try:
                    result = json.loads(result)
                except:
                    print(f"   ‚ö†Ô∏è Respuesta no es JSON v√°lido")
                    print(f"   Primeros 200 chars: {result[:200]}")
                    continue
            
            if 'paginas_texto' in result:
                num_paginas = len(result['paginas_texto'])
                print(f"   ‚úì {num_paginas} p√°ginas generadas")
                
                # Verificar primera p√°gina
                if '1' in result['paginas_texto']:
                    p1 = result['paginas_texto']['1']
                    versos = p1.count('\\n') + 1
                    print(f"   ‚úì P√°gina 1 tiene {versos} versos")
                    print(f"   Muestra: {p1[:50]}...")
            else:
                print(f"   ‚ö†Ô∏è No tiene campo 'paginas_texto'")
                print(f"   Claves: {list(result.keys())}")
            
            # Guardar el exitoso
            with open(f'cuentacuentos_exitoso_{max_tokens}.json', 'w') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"   üíæ Guardado en cuentacuentos_exitoso_{max_tokens}.json")
            
            return True
            
        except ValueError as ve:
            elapsed = time.time() - start
            print(f"‚ùå FALLO en {elapsed:.1f}s: {ve}")
            if "no gener√≥ contenido" in str(ve):
                print(f"   ‚Üí El modelo devolvi√≥ vac√≠o con {max_tokens} tokens")
        except Exception as e:
            print(f"‚ùå ERROR: {e}")
    
    return False

if __name__ == "__main__":
    success = test_simple()
    if not success:
        print("\n‚ö†Ô∏è Todas las configuraciones fallaron")
        print("El modelo no puede generar el contenido requerido")
    else:
        print("\n‚ú® Al menos una configuraci√≥n funcion√≥")